{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DI 725 Project Phase 2 - Ali Yiğit Başaran - 2231355 \n",
    "#### Dataset Preparation - Modeling - Train, Validation Loop - Test & Log Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "# ! pip install -U -q transformers accelerate datasets\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "import re\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:42:19.731548Z",
     "iopub.status.busy": "2025-05-14T09:42:19.731156Z",
     "iopub.status.idle": "2025-05-14T09:42:20.141178Z",
     "shell.execute_reply": "2025-05-14T09:42:20.140267Z",
     "shell.execute_reply.started": "2025-05-14T09:42:19.731505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>image</th>\n",
       "      <th>filtered_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31430.jpg</td>\n",
       "      <td>A plane is parked on the runway next to the gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31431.jpg</td>\n",
       "      <td>Four planes of different sizes were on the mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31432.jpg</td>\n",
       "      <td>A plane parked in a line on the airport with s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31433.jpg</td>\n",
       "      <td>Two planes of different sizes are neatly parke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NWPU</td>\n",
       "      <td>test</td>\n",
       "      <td>NWPU_31434.jpg</td>\n",
       "      <td>Two aircraft were parked at the departure gates .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source split           image  \\\n",
       "0   NWPU  test  NWPU_31430.jpg   \n",
       "1   NWPU  test  NWPU_31431.jpg   \n",
       "2   NWPU  test  NWPU_31432.jpg   \n",
       "3   NWPU  test  NWPU_31433.jpg   \n",
       "4   NWPU  test  NWPU_31434.jpg   \n",
       "\n",
       "                                    filtered_caption  \n",
       "0  A plane is parked on the runway next to the gr...  \n",
       "1  Four planes of different sizes were on the mar...  \n",
       "2  A plane parked in a line on the airport with s...  \n",
       "3  Two planes of different sizes are neatly parke...  \n",
       "4  Two aircraft were parked at the departure gates .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/riscm-dataset/filtered_captions_fixed.csv\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Paligemma Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:42:20.142931Z",
     "iopub.status.busy": "2025-05-14T09:42:20.142640Z",
     "iopub.status.idle": "2025-05-14T09:42:20.336484Z",
     "shell.execute_reply": "2025-05-14T09:42:20.335796Z",
     "shell.execute_reply.started": "2025-05-14T09:42:20.142904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /kaggle/input/paligemma-2/transformers/paligemma2-3b-pt-224/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "# path = kagglehub.model_download(\"google/paligemma-2/transformers/paligemma2-3b-pt-224\")\n",
    "# if you have downloaded weights before, use their path:\n",
    "path = \"/kaggle/input/paligemma-2/transformers/paligemma2-3b-pt-224/1\"\n",
    "\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and LoRA Param Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:42:20.337378Z",
     "iopub.status.busy": "2025-05-14T09:42:20.337204Z",
     "iopub.status.idle": "2025-05-14T09:42:36.168381Z",
     "shell.execute_reply": "2025-05-14T09:42:36.167739Z",
     "shell.execute_reply.started": "2025-05-14T09:42:20.337362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 09:42:25.093135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747215745.116327     137 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747215745.123339     137 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3873e52ad154af78d6b95e78e00cd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    local_files_only=True\n",
    ").to(device)\n",
    "processor = PaliGemmaProcessor.from_pretrained(path, local_files_only=True)\n",
    "\n",
    "# The training and evaluation is done for Lora-1 and Lora-2 Hyperparams\n",
    "\n",
    "# Lora-1 Hyperparams\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.2,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "# Lora-2 Hyperparams\n",
    "# lora_config = LoraConfig(\n",
    "#     r=2,\n",
    "#     lora_alpha=4,\n",
    "#     lora_dropout=0.1,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     target_modules=[\"q_proj\", \"o_proj\"]\n",
    "# )\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# Total trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Freezing everything but the attention layers\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"attn\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        \n",
    "# Trainable attention layer parameters\n",
    "attn_params = sum(\n",
    "    p.numel() for name, p in model.named_parameters()\n",
    "    if p.requires_grad and \"attn\" in name\n",
    ")\n",
    "\n",
    "print(f\"Total trainable parameters: {total_params}\")\n",
    "print(f\"Trainable attention parameters: {attn_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preaparation and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Split data according to train-val-test and remove unused columns (such split and source after preparing datasets)\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "val_df = df[df[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "test_df = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "train_df = train_df.drop(columns=[\"source\", \"split\"])\n",
    "val_df = val_df.drop(columns=[\"source\", \"split\"])\n",
    "test_df = test_df.drop(columns=[\"source\", \"split\"])\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_dir = \"/kaggle/input/riscm-dataset/RISCM/resized\"\n",
    "\n",
    "# Create Data Loader\n",
    "def collate_train_fn(examples):\n",
    "    images = [Image.open(os.path.join(image_dir, ex[\"image\"])).convert(\"RGB\") for ex in examples]\n",
    "    prompt = [\"caption the image\" for _ in examples]\n",
    "    suffix = [example[\"filtered_caption\"] for example in examples]\n",
    "\n",
    "    inputs = processor(\n",
    "        images=images,\n",
    "        text=prompt,\n",
    "        suffix=suffix,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",\n",
    "    )\n",
    "\n",
    "    inputs = inputs.to(torch.bfloat16).to(device)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def collate_test_fn(examples):\n",
    "    images = [Image.open(os.path.join(image_dir, ex[\"image\"])).convert(\"RGB\") for ex in examples]\n",
    "\n",
    "    prompt = [\"caption the image\" for _ in examples]\n",
    "\n",
    "    inputs = processor(\n",
    "        images=images,\n",
    "        text=prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"longest\",\n",
    "    )\n",
    "\n",
    "    inputs = inputs.to(torch.bfloat16).to(device)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=collate_train_fn,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=collate_train_fn,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=collate_test_fn,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:42:36.174401Z",
     "iopub.status.busy": "2025-05-14T09:42:36.174141Z",
     "iopub.status.idle": "2025-05-14T09:42:36.187564Z",
     "shell.execute_reply": "2025-05-14T09:42:36.186847Z",
     "shell.execute_reply.started": "2025-05-14T09:42:36.174382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "\n",
    "# Set W&B API key in the environment\n",
    "os.environ[\"WANDB_API_KEY\"] = \"1640c7993fb7d40efc5ce820586098b3f8a569f4\"\n",
    "\n",
    "# Login to wandb\n",
    "wandb.login()\n",
    "\n",
    "# Choose the run name according to the lora param configuration\n",
    "wandb.init(reinit=True, project=\"DI725_Project\", name=\"paligemma-lora-ft-kaggle-lora1\")\n",
    "# wandb.init(reinit=True, project=\"DI725_Project\", name=\"paligemma-lora-ft-kaggle-lora2\")\n",
    "\n",
    "model = model.to(dtype=torch.bfloat16, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T09:42:37.317738Z",
     "iopub.status.busy": "2025-05-14T09:42:37.317014Z",
     "iopub.status.idle": "2025-05-14T09:42:37.321627Z",
     "shell.execute_reply": "2025-05-14T09:42:37.320795Z",
     "shell.execute_reply.started": "2025-05-14T09:42:37.317716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import deque\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "NUMBER_OF_TRAIN_LOSS_LOG = 100\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate,weight_decay = 1e-3)\n",
    "num_training_steps = len(train_dataloader) * NUM_EPOCHS\n",
    "num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "loss_window = deque(maxlen=NUMBER_OF_TRAIN_LOSS_LOG)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_train_loss = 0\n",
    "    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch {epoch+1}\")\n",
    "    # Training Loop\n",
    "    for idx, batch in progress_bar:\n",
    "        # batch = {k: v.to(torch.bfloat16).to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_window.append(loss.item())\n",
    "\n",
    "        # print(f\"Epoch: {epoch+1} Iter: {idx} Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "        if idx % NUMBER_OF_TRAIN_LOSS_LOG == 0 and len(loss_window) == NUMBER_OF_TRAIN_LOSS_LOG:\n",
    "            avg_last_runs = sum(loss_window) / NUMBER_OF_TRAIN_LOSS_LOG\n",
    "            wandb.log({\n",
    "                \"train_loss\": avg_last_runs,\n",
    "                \"step\": epoch * len(train_dataloader) + idx,\n",
    "                \"learning_rate\": scheduler.get_last_lr()[0]\n",
    "            })\n",
    "    # Validate the model per end of epochs\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_dataloader:\n",
    "            val_outputs = model(**val_batch)\n",
    "            val_loss = val_outputs.loss\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "    # Calculate average losses\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    scheduler.step(avg_val_loss)\n",
    "    wandb.log({\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"epoch\": epoch + 1,\n",
    "    })\n",
    "    for param_group in optimizer.param_groups:\n",
    "      print(f\"Epoch {epoch+1} | Avg Train Loss: {avg_train_loss:.4f} | Avg Val Loss: {avg_val_loss:.4f} Learning Rate: {param_group['lr']:.6f}\\n\")\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model weights after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "# Choose the save path according to the lora config (1 or 2)\n",
    "\n",
    "# Define save path\n",
    "final_output_dir = \"/kaggle/working/model\"\n",
    "os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "# Save model and processor\n",
    "model.save_pretrained(final_output_dir)\n",
    "processor.save_pretrained(final_output_dir)\n",
    "\n",
    "# Create and log W&B artifact\n",
    "artifact = wandb.Artifact(\"paligemma-lora1-model\", type=\"model\")\n",
    "artifact.add_dir(final_output_dir)\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# # Define save path\n",
    "# final_output_dir = \"/kaggle/working/model\"\n",
    "# os.makedirs(final_output_dir, exist_ok=True)\n",
    "\n",
    "# # Save model and processor\n",
    "# model.save_pretrained(final_output_dir)\n",
    "# processor.save_pretrained(final_output_dir)\n",
    "\n",
    "# # Create and log W&B artifact\n",
    "# artifact = wandb.Artifact(\"paligemma-lora2-model\", type=\"model\")\n",
    "# artifact.add_dir(final_output_dir)\n",
    "# wandb.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on the test set and log bleu, rouge and meteor metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import wandb\n",
    "from evaluate import load\n",
    "\n",
    "# Load evaluation metrics\n",
    "bleu = load(\"bleu\")\n",
    "rouge = load(\"rouge\")\n",
    "meteor = load(\"meteor\")\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "# === Helper Function ===\n",
    "def read_image(path):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "    if image.shape[-1] == 4:\n",
    "        image = image[:, :, :3]\n",
    "    return image\n",
    "# Evaluate only on test_df\n",
    "for i, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Evaluating\"):\n",
    "    image_path = os.path.join(\"./RISCM/resized\", row[\"image\"])\n",
    "    try:\n",
    "        image = read_image(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Skipped {image_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    input_text = \"caption the image\\n\"\n",
    "    inputs = processor(\n",
    "        text=input_text,\n",
    "        images=image,\n",
    "        do_convert_rgb=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(base_model.device)\n",
    "\n",
    "    inputs = inputs.to(dtype=base_model.dtype)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = base_model.generate(**inputs, max_new_tokens=64)\n",
    "\n",
    "    decoded = processor.decode(output[0], skip_special_tokens=True)\n",
    "    cleaned = decoded.lower().replace(\"caption the image\", \"\").strip(\" :.-\").strip()\n",
    "\n",
    "    predictions.append(cleaned)\n",
    "    references.append(row[\"filtered_caption\"])\n",
    "    \n",
    "# Compute final scores\n",
    "bleu_refs = [[ref] for ref in references]\n",
    "bleu_score = bleu.compute(predictions=predictions, references=bleu_refs)[\"bleu\"]\n",
    "rouge_score = rouge.compute(predictions=predictions, references=references)[\"rougeL\"]\n",
    "meteor_score = meteor.compute(predictions=predictions, references=references)[\"meteor\"]\n",
    "\n",
    "# Log to wandb\n",
    "wandb.log({\n",
    "    \"test_bleu\": bleu_score,\n",
    "    \"test_rougeL\": rouge_score,\n",
    "    \"test_meteor\": meteor_score\n",
    "})\n",
    "\n",
    "# Log sample predictions\n",
    "wandb_table = wandb.Table(columns=[\"Prediction\", \"Ground Truth\"])\n",
    "for pred, ref in zip(predictions[:50], references[:50]):\n",
    "    wandb_table.add_data(pred, ref)\n",
    "\n",
    "wandb.log({\"test_predictions_table\": wandb_table})\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7414659,
     "sourceId": 11806391,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7415183,
     "sourceId": 11807115,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 239633731,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 164716,
     "modelInstanceId": 158308,
     "sourceId": 185693,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
